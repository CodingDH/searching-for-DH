{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Initial Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from data_generation_scripts.general_utils import *\n",
    "from data_generation_scripts.generate_entity_metadata import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../new_datasets'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_directory_path = get_data_directory_path()\n",
    "data_directory_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Initial Queries Datasets and Get Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Walking through directories: 9it [00:00, 436.49it/s]\n",
      "Processing queries:   0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 17/17 [00:00<00:00, 303.18it/s]\n",
      "Walking through directories: 9it [00:00, 276.01it/s]\n",
      "Processing queries: 100%|██████████| 74/74 [00:00<00:00, 98.60it/s] \n"
     ]
    }
   ],
   "source": [
    "data_directory_path = \"../../new_datasets\"\n",
    "target_terms: list = [\"Public History\", \"Digital History\", \"Digital Cultural Heritage\", \"Cultural Analytics\", \"Computational Humanities\", \"Computational Social Science\", \"Digital Humanities\"]\n",
    "\n",
    "# Load in the translated terms\n",
    "cleaned_terms = pd.read_csv(f'{data_directory_path}/derived_files/grouped_cleaned_translated_terms.csv', encoding='utf-8-sig')\n",
    "\n",
    "if 'keep_term' in cleaned_terms.columns:\n",
    "    cleaned_terms = cleaned_terms[cleaned_terms.keep_term == True]\n",
    "# check if columns need renaming\n",
    "columns_to_rename = ['code', 'term', 'term_source']\n",
    "if all(elem in cleaned_terms.columns for elem in columns_to_rename):\n",
    "    cleaned_terms = cleaned_terms.rename(columns={'code': 'natural_language', 'term': 'search_term', 'term_source': 'search_term_source'})\n",
    "cleaned_terms = cleaned_terms[cleaned_terms.search_term_source.isin(target_terms)]\n",
    "cleaned_terms = cleaned_terms.reset_index(drop=True)\n",
    "\n",
    "cleaned_terms.loc[cleaned_terms.search_term.str.contains(\"&#39;\"), \"search_term\"] = cleaned_terms.search_term.str.replace(\"&#39;\", \"'\")\n",
    "cleaned_terms['lower_search_term'] = cleaned_terms.search_term.str.lower()\n",
    "\n",
    "search_user_queries_df = create_queries_directories(\"user\", cleaned_terms)\n",
    "search_org_queries_df = search_user_queries_df[search_user_queries_df['type'] == 'Organization']\n",
    "search_org_queries_df = search_org_queries_df[search_org_queries_df.search_term_source.isin(cleaned_terms.search_term_source.unique())]\n",
    "search_user_queries_df = search_user_queries_df[search_user_queries_df['type'] == 'User']\n",
    "search_user_queries_df = search_user_queries_df[search_user_queries_df.search_term_source.isin(cleaned_terms.search_term_source.unique())]\n",
    "search_repo_queries_df = create_queries_directories(\"repo\", cleaned_terms)\n",
    "search_repo_queries_df = search_repo_queries_df[search_repo_queries_df.search_term_source.isin(cleaned_terms.search_term_source.unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entity_type = \"repos\"\n",
    "# potential_new_entities_df = search_repo_queries_df.drop_duplicates(subset=['full_name'])\n",
    "# temp_entity_dir = f\"{data_directory_path}/historic_data/entity_files/all_repos/\"\n",
    "# entity_progress_bar = tqdm(total=potential_new_entities_df.shape[0], desc=\"Processing entities\")\n",
    "# error_file_path = f\"{data_directory_path}/error_logs/repo_errors.csv\"\n",
    "# get_new_entities(entity_type, potential_new_entities_df, temp_entity_dir, entity_progress_bar, error_file_path)\n",
    "\n",
    "# entity_type = \"orgs\"\n",
    "# potential_new_entities_df = search_org_queries_df.drop_duplicates(subset=['login'])\n",
    "# temp_entity_dir = f\"{data_directory_path}/historic_data/entity_files/all_orgs/\"\n",
    "# entity_progress_bar = tqdm(total=potential_new_entities_df.shape[0], desc=\"Processing entities\")\n",
    "# error_file_path = f\"{data_directory_path}/error_logs/org_errors.csv\"\n",
    "# get_new_entities(entity_type, potential_new_entities_df, temp_entity_dir, entity_progress_bar, error_file_path)\n",
    "\n",
    "# entity_type = \"users\"\n",
    "# potential_new_entities_df = search_user_queries_df.drop_duplicates(subset=['login'])\n",
    "# temp_entity_dir = f\"{data_directory_path}/historic_data/entity_files/all_users/\"\n",
    "# entity_progress_bar = tqdm(total=potential_new_entities_df.shape[0], desc=\"Processing entities\")\n",
    "# error_file_path = f\"{data_directory_path}/error_logs/user_errors.csv\"\n",
    "# get_new_entities(entity_type, potential_new_entities_df, temp_entity_dir, entity_progress_bar, error_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Digital Humanities              4018\n",
       "Digital History                 1141\n",
       "Computational Social Science     786\n",
       "Cultural Analytics               473\n",
       "Computational Humanities         354\n",
       "Public History                    94\n",
       "Digital Cultural Heritage         44\n",
       "Name: search_term_source, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_repo_queries_df.search_term_source.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1262, 1952, 246, 426, 4528, 6910)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_user_queries_df.login.nunique(), len(search_user_queries_df), search_org_queries_df.login.nunique(), len(search_org_queries_df), search_repo_queries_df.full_name.nunique(), len(search_repo_queries_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_files = os.listdir(f\"{data_directory_path}/historic_data/entity_files/all_users/\")\n",
    "org_files = os.listdir(f\"{data_directory_path}/historic_data/entity_files/all_orgs/\")\n",
    "repo_files = os.listdir(f\"{data_directory_path}/historic_data/entity_files/all_repos/\")\n",
    "cleaned_user_files = [f.split(\"_coding_dh_\")[0] for f in user_files if f.endswith(\".csv\")]\n",
    "cleaned_org_files = [f.split(\"_coding_dh_\")[0] for f in org_files if f.endswith(\".csv\")]\n",
    "cleaned_repo_files = [f.split(\"_coding_dh_\")[0].replace(\"_\", \"/\", 1) for f in repo_files if f.endswith(\".csv\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_search_user_queries_df = search_user_queries_df[search_user_queries_df.login.isin(cleaned_user_files)]\n",
    "existing_search_org_queries_df = search_org_queries_df[search_org_queries_df.login.isin(cleaned_org_files)]\n",
    "existing_search_repo_queries_df = search_repo_queries_df[search_repo_queries_df.full_name.isin(cleaned_repo_files)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1262, 1952, 246, 426, 4525, 6907)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existing_search_user_queries_df.login.nunique(), len(existing_search_user_queries_df), existing_search_org_queries_df.login.nunique(), len(existing_search_org_queries_df), existing_search_repo_queries_df.full_name.nunique(), len(existing_search_repo_queries_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalized_user_logins = existing_search_user_queries_df.login.unique().tolist()\n",
    "finalized_org_logins = existing_search_org_queries_df.login.unique().tolist()\n",
    "finalized_repo_full_names = existing_search_repo_queries_df.full_name.unique().tolist()\n",
    "\n",
    "finalized_user_files = [f\"{login}_coding_dh_user.csv\" for login in finalized_user_logins]\n",
    "finalized_org_files = [f\"{login}_coding_dh_org.csv\" for login in finalized_org_logins]\n",
    "finalized_repo_files = [f\"{full_name.replace('/', '_')}_coding_dh_repo.csv\" for full_name in finalized_repo_full_names]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial core datasets will be comprised of the following:\n",
    "\n",
    "- `core_repos`: A list of all repos that were returned by the search query\n",
    "- `core_users`: A list of all users that were returned by the search query\n",
    "- `core_orgs`: A list of all orgs that were returned by the search query"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "values_and_versions_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
